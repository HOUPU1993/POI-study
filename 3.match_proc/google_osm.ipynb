{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9469bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from typing import Optional\n",
    "from pyiceberg.expressions import And, GreaterThanOrEqual, LessThanOrEqual\n",
    "from pyiceberg.catalog import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8832e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def search_spatial_candidates(\n",
    "    reference_gdf: gpd.GeoDataFrame,\n",
    "    compared_gdf: gpd.GeoDataFrame,\n",
    "    k: int = 100,\n",
    "    max_dist: float = 1000, \n",
    "    id_col: str = \"id\",\n",
    "    crs_for_distance: int = 3857,\n",
    "):\n",
    "    \"\"\"\n",
    "    Attach k nearest compared POI ids & distances to reference_gdf.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame with two new columns:\n",
    "    - cand_ids   : list of compared ids\n",
    "    - cand_dist_m: list of distances (meters)\n",
    "    \"\"\"\n",
    "\n",
    "    ref_proj = reference_gdf.to_crs(crs_for_distance)\n",
    "    cmp_proj = compared_gdf.to_crs(crs_for_distance)\n",
    "\n",
    "    ref_xy = np.column_stack([ref_proj.geometry.x, ref_proj.geometry.y])\n",
    "    cmp_xy = np.column_stack([cmp_proj.geometry.x, cmp_proj.geometry.y])\n",
    "\n",
    "    tree = cKDTree(cmp_xy)\n",
    "    k_eff = min(k, len(compared_gdf))\n",
    "\n",
    "    dist, idx = tree.query(ref_xy, k=k_eff)\n",
    "\n",
    "    if k_eff == 1:\n",
    "        dist = dist.reshape(-1, 1)\n",
    "        idx = idx.reshape(-1, 1)\n",
    "\n",
    "    cmp_ids = compared_gdf[id_col].to_numpy()\n",
    "\n",
    "    cand_ids = []\n",
    "    cand_dists = []\n",
    "\n",
    "    for row_idx, row_dist in zip(idx, dist):\n",
    "        ids = []\n",
    "        dists = []\n",
    "\n",
    "        for j, d in zip(row_idx, row_dist):\n",
    "            if d <= max_dist:\n",
    "                ids.append(cmp_ids[j])\n",
    "                dists.append(d)\n",
    "\n",
    "        cand_ids.append(ids)\n",
    "        cand_dists.append(dists)\n",
    "\n",
    "    result = reference_gdf.copy()\n",
    "    result[\"cand_ids\"] = cand_ids\n",
    "    result[\"cand_dist_m\"] = cand_dists\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6e2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_WORDS = {\n",
    "    \"RESTAURANT\",\"RESTURANT\",\"RESTARAUNT\",\n",
    "    \"CAFE\",\"CAFÉ\",\"COFFEE\",\"BAR\",\"BISTRO\",\"GRILL\",\n",
    "    \"KITCHEN\",\"DINER\",\"EATERY\",\"STEAKHOUSE\",\n",
    "    \"SEAFOOD\",\"BUFFET\",\"BBQ\",\"PIZZA\",\"SUSHI\",\"RAMEN\",\n",
    "    \"NOODLE\",\"NOODLES\",\"BURGER\",\"BURGERS\",\"TACO\",\"TACOS\",\n",
    "    \"CHICKEN\",\"WINGS\",\"BAKERY\",\"DELI\",\"DELICATESSEN\",\n",
    "    \"COURT\",\"FOOD\",\"EXPRESS\",\"HOUSE\",\"SHOP\"\n",
    "}\n",
    "\n",
    "PLACE_WORDS = {\n",
    "    \"HALL\",\"CENTER\",\"CENTRE\",\"PLAZA\",\"MARKET\",\"MALL\",\n",
    "    \"GARDEN\",\"GARDENS\",\"PARK\",\"SQUARE\",\"TOWER\",\"TOWERS\",\n",
    "    \"STATION\",\"TERMINAL\",\"BUILDING\",\"GALLERY\",\"THEATER\",\"SCHOOL\",\"COURT\",\"INN\",\n",
    "    \"HOTEL\",\"MOTEL\",\"INN\",\"SUITES\",\"SUITE\",\n",
    "    \"SPA\",\"SALON\",\"STUDIO\",\"CENTER\",\"CENTRE\",\n",
    "    \"CLUB\",\"LOUNGE\",\"STATION\",\"STOP\"\n",
    "}\n",
    "\n",
    "LEGAL_WORDS = {\n",
    "    \"LLC\",\"INC\",\"CORP\",\"CORPORATION\",\"CO\",\"COMPANY\",\n",
    "    \"LTD\",\"LIMITED\",\"GROUP\",\"HOLDINGS\",\"OFFICE\"\n",
    "}\n",
    "\n",
    "GRAMMAR = {\n",
    "    \"THE\",\"OF\",\"AT\",\"AND\",\"FOR\",\"IN\",\"ON\",\"BY\",\"WITH\",\"TO\",\"FROM\"\n",
    "}\n",
    "\n",
    "NON_PRIMARY_TOKENS = FOOD_WORDS | PLACE_WORDS | LEGAL_WORDS | GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a383b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def clean_name(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c)) # 1. unicode normalize (remove accents)\n",
    "    s = s.upper() # 2. uppercase\n",
    "    s = re.sub(r\"\\([^)]*\\)\", \"\", s) \n",
    "    s = re.sub(r\"\\b'S\\b\", \"\", s) # new change\n",
    "    s = re.sub(r\"\\bS\\b\", \"\", s) # new change\n",
    "    s = s.encode(\"ascii\", errors=\"ignore\").decode() # 4. remove emoji / non ascii\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s) # 5. replace special chars with space\n",
    "    s = re.sub(r\"\\s+\", \" \", s) # 6. collapse spaces\n",
    "\n",
    "    return s.strip()\n",
    "\n",
    "def extract_prinmary_str(name):\n",
    "\n",
    "    tokens = name.split()\n",
    "    core = [t for t in tokens if t not in NON_PRIMARY_TOKENS]\n",
    "    if len(core) == 1 and len(core[0]) < 3:\n",
    "        return name\n",
    "    if core:\n",
    "        return \" \".join(core)\n",
    "    return name\n",
    "\n",
    "def match_by_name(\n",
    "    reference_gdf: gpd.GeoDataFrame,\n",
    "    compared_gdf: gpd.GeoDataFrame,\n",
    "    re_name_col: str = \"name\",\n",
    "    comp_name_col: str = \"name\",\n",
    "    comp_id: str = \"id\",\n",
    "    comp_id_col: str=\"cat_main\",\n",
    "    threshold: int = 80,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform WRatio name matching within spatial candidates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame with:\n",
    "    - matched_id_name\n",
    "    - name_score\n",
    "    \"\"\"\n",
    "\n",
    "    # clean names for matching\n",
    "    id_to_name_clean = compared_gdf.set_index(comp_id)[comp_name_col].apply(clean_name).apply(extract_prinmary_str).to_dict()\n",
    "    # raw names for storage\n",
    "    id_to_name_raw = compared_gdf.set_index(comp_id)[comp_name_col].to_dict()\n",
    "    # raw compared df category\n",
    "    id_to_cat = compared_gdf.set_index(comp_id)[comp_id_col].to_dict()\n",
    "\n",
    "    matched_ids = []\n",
    "    scores = []\n",
    "    loc_dists = []\n",
    "    matched_names = []\n",
    "    matched_cats = []\n",
    "\n",
    "    for _, row in reference_gdf.iterrows():\n",
    "        query = extract_prinmary_str(clean_name(row.get(re_name_col)))\n",
    "\n",
    "        if not isinstance(query, str) or not row[\"cand_ids\"]:\n",
    "            matched_ids.append(pd.NA)\n",
    "            scores.append(pd.NA)\n",
    "            loc_dists.append(pd.NA)\n",
    "            matched_names.append(pd.NA)\n",
    "            matched_cats.append(pd.NA)\n",
    "            continue\n",
    "\n",
    "        cand_names = [id_to_name_clean.get(cid, \"\") for cid in row[\"cand_ids\"]]\n",
    "\n",
    "        top_matches = process.extract(\n",
    "            query,\n",
    "            cand_names,\n",
    "            scorer=fuzz.WRatio,\n",
    "            limit=5\n",
    "        )\n",
    "\n",
    "        best_score = -1\n",
    "        best_pos = None\n",
    "\n",
    "        for name, wr, pos in top_matches:\n",
    "\n",
    "            pr = fuzz.partial_ratio(query, name)\n",
    "            ts = fuzz.token_sort_ratio(query, name)\n",
    "            tset = fuzz.token_set_ratio(query, name)\n",
    "\n",
    "            combined = max(wr, pr, ts, tset)\n",
    "\n",
    "            if combined > best_score:\n",
    "                best_score = combined\n",
    "                best_pos = pos\n",
    "\n",
    "        score = best_score\n",
    "\n",
    "        if score >= threshold:\n",
    "            matched_ids.append(row[\"cand_ids\"][best_pos])\n",
    "            scores.append(score)\n",
    "            loc_dists.append(row[\"cand_dist_m\"][best_pos])\n",
    "            matched_names.append(id_to_name_raw.get(row[\"cand_ids\"][best_pos]))\n",
    "            matched_cats.append(id_to_cat.get(row[\"cand_ids\"][best_pos]))\n",
    "        else:\n",
    "            matched_ids.append(pd.NA)\n",
    "            scores.append(score)\n",
    "            loc_dists.append(pd.NA)\n",
    "            matched_names.append(pd.NA)\n",
    "            matched_cats.append(pd.NA)\n",
    "\n",
    "\n",
    "    result = reference_gdf.copy()\n",
    "    result[\"matched_id\"] = matched_ids\n",
    "    result[\"name_score\"] = scores\n",
    "    result[\"location_distance\"] = loc_dists\n",
    "    result[\"matched_name\"] = matched_names\n",
    "    result[\"matched_cat_main\"] = matched_cats\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46899453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_name(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c)) # 1. unicode normalize (remove accents)\n",
    "    s = s.upper() # 2. uppercase\n",
    "    s = re.sub(r\"\\([^)]*\\)\", \"\", s) \n",
    "    s = s.encode(\"ascii\", errors=\"ignore\").decode() # 4. remove emoji / non ascii\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s) # 5. replace special chars with space\n",
    "    s = re.sub(r\"\\s+\", \" \", s) # 6. collapse spaces\n",
    "\n",
    "    return s.strip()\n",
    "\n",
    "def address_score_check(\n",
    "    reference_gdf: gpd.GeoDataFrame,\n",
    "    compared_gdf: gpd.GeoDataFrame,\n",
    "    addr_col_ref: str = \"addr_simple\",\n",
    "    addr_col_cmp: str = \"address\",\n",
    "    matched_id_col: str = \"matched_id\",\n",
    "    id_col: str = \"id\",\n",
    "    out_col: str = \"address_score\",\n",
    "    out_addr_col: str = \"matched_address\", \n",
    "):\n",
    "    \"\"\"\n",
    "    Compute address similarity score (0-100) for already-matched rows.\n",
    "\n",
    "    Only rows with non-null `matched_id_col` will be scored.\n",
    "    Others will have NaN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame with a new column `out_col`.\n",
    "    \"\"\"\n",
    "\n",
    "    # map: compared id -> compared address\n",
    "    id_to_addr_clean = compared_gdf.set_index(id_col)[addr_col_cmp].apply(clean_name).to_dict()\n",
    "    id_to_addr_raw = compared_gdf.set_index(id_col)[addr_col_cmp].to_dict()\n",
    "\n",
    "    scores = []\n",
    "    matched_addrs = []\n",
    "\n",
    "    for _, row in reference_gdf.iterrows():\n",
    "        matched_id = row.get(matched_id_col)\n",
    "\n",
    "        # no matched id -> no score\n",
    "        if pd.isna(matched_id):\n",
    "            scores.append(pd.NA)\n",
    "            matched_addrs.append(pd.NA)\n",
    "            continue\n",
    "\n",
    "        addr_ref = clean_name(row.get(addr_col_ref))\n",
    "        addr_cmp = id_to_addr_clean.get(matched_id)\n",
    "\n",
    "        if isinstance(addr_cmp, str) and addr_cmp.strip():\n",
    "            matched_addrs.append(id_to_addr_raw.get(matched_id))\n",
    "        else:\n",
    "            matched_addrs.append(pd.NA)\n",
    "\n",
    "        # missing address on either side -> no score\n",
    "        if not isinstance(addr_ref, str) or not addr_ref.strip():\n",
    "            scores.append(pd.NA)\n",
    "            continue\n",
    "        if not isinstance(addr_cmp, str) or not addr_cmp.strip():\n",
    "            scores.append(pd.NA)\n",
    "            continue\n",
    "\n",
    "        wr = fuzz.WRatio(addr_ref, addr_cmp)\n",
    "        pr = fuzz.partial_ratio(addr_ref, addr_cmp)\n",
    "        ts = fuzz.token_sort_ratio(addr_ref, addr_cmp)\n",
    "        tset = fuzz.token_set_ratio(addr_ref, addr_cmp)\n",
    "\n",
    "        scores.append(int(max(wr, pr, ts, tset)))\n",
    "\n",
    "    result = reference_gdf.copy()\n",
    "    result[out_col] = scores\n",
    "    result[out_addr_col] = matched_addrs\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64bd335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_similarity_check(\n",
    "    df, \n",
    "    cat_col_ref: str = \"primary_type\", \n",
    "    cat_col_cmp: str = \"matched_cat_main\", \n",
    "    id_col: str = \"matched_id\", \n",
    "    result_col: str =  \"category_sim\",\n",
    "):\n",
    "\n",
    "    # 1. Setup Device\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "    \n",
    "    # 2. Primary Gatekeeper: matched_id must be present\n",
    "    mask = df[id_col].notna() & (df[id_col].astype(str).str.strip() != \"\")\n",
    "    \n",
    "    # 3. Create a helper to handle potential Nulls in text columns\n",
    "    temp_df = df[mask].copy()\n",
    "    \n",
    "    # Identify where text is actually missing within the masked rows\n",
    "    text_missing_mask = temp_df[cat_col_ref].isna() | temp_df[cat_col_cmp].isna()\n",
    "    \n",
    "    # Fill NaNs with empty strings just for the encoding step\n",
    "    texts_1 = temp_df[cat_col_ref].fillna(\"\").astype(str).tolist()\n",
    "    texts_2 = temp_df[cat_col_cmp].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    print(f\"Encoding {len(temp_df)} rows...\")\n",
    "\n",
    "    # 4. Batch Encoding\n",
    "    emb1 = model.encode(texts_1, batch_size=256, show_progress_bar=True, convert_to_tensor=True)\n",
    "    emb2 = model.encode(texts_2, batch_size=256, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "    # 5. Calculate Similarity\n",
    "    scores = torch.nn.functional.cosine_similarity(emb1, emb2, dim=1).cpu().numpy()\n",
    "    \n",
    "    # 6. Apply NaN to rows where text was missing\n",
    "    # Even if we encoded an empty string, the result isn't \"real\" if data was missing\n",
    "    scores[text_missing_mask.values] = np.nan\n",
    "\n",
    "    # 7. Map back to original dataframe\n",
    "    df[result_col] = np.nan\n",
    "    df.loc[mask, result_col] = scores\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d4b33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>primary_cat</th>\n",
       "      <th>geometry</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>naics_definition</th>\n",
       "      <th>addr_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ChIJwTqOxGO1kVQR3ffcwUqPDTc</td>\n",
       "      <td>Safeway Fuel Station</td>\n",
       "      <td>23961 WA-3, Belfair, WA 98528, USA</td>\n",
       "      <td>gas_station</td>\n",
       "      <td>47.453613</td>\n",
       "      <td>-122.824365</td>\n",
       "      <td>automotive</td>\n",
       "      <td>POINT (-122.82436 47.45361)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>23961 WA-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ChIJpZyerHu1kVQRAc6e7nFRTOA</td>\n",
       "      <td>Local Wrench</td>\n",
       "      <td>23530 WA-3 suite a, Belfair, WA 98528, USA</td>\n",
       "      <td>car_repair</td>\n",
       "      <td>47.447925</td>\n",
       "      <td>-122.828294</td>\n",
       "      <td>automotive</td>\n",
       "      <td>POINT (-122.82829 47.44793)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Other Services (except Public Administration)</td>\n",
       "      <td>23530 WA-3 suite a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ChIJ8SIqjWO1kVQR2blnwrvt0C4</td>\n",
       "      <td>Valvoline Instant Oil Change</td>\n",
       "      <td>23970 N WA-3, Belfair, WA 98528, USA</td>\n",
       "      <td>car_repair</td>\n",
       "      <td>47.453070</td>\n",
       "      <td>-122.822240</td>\n",
       "      <td>automotive</td>\n",
       "      <td>POINT (-122.82224 47.45307)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Other Services (except Public Administration)</td>\n",
       "      <td>23970 N WA-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ChIJ4ZaLfGO1kVQRKZIPKm91JmA</td>\n",
       "      <td>Chevron Belfair</td>\n",
       "      <td>23880 WA-3, Belfair, WA 98528, USA</td>\n",
       "      <td>gas_station</td>\n",
       "      <td>47.452338</td>\n",
       "      <td>-122.824376</td>\n",
       "      <td>automotive</td>\n",
       "      <td>POINT (-122.82438 47.45234)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>23880 WA-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ChIJOYTHKWO1kVQRRXwvopTyBVw</td>\n",
       "      <td>QFC Fuel Center</td>\n",
       "      <td>201 WA-300, Belfair, WA 98528, USA</td>\n",
       "      <td>gas_station</td>\n",
       "      <td>47.453683</td>\n",
       "      <td>-122.827552</td>\n",
       "      <td>automotive</td>\n",
       "      <td>POINT (-122.82755 47.45368)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>201 WA-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>42</td>\n",
       "      <td>ChIJD6bA4-Xgj1QRg1RuvTgcXe0</td>\n",
       "      <td>Paradise Bay Rd &amp; S Bay Lane</td>\n",
       "      <td>Port Ludlow, WA 98365, USA</td>\n",
       "      <td>bus_stop</td>\n",
       "      <td>47.912121</td>\n",
       "      <td>-122.692577</td>\n",
       "      <td>transportation</td>\n",
       "      <td>POINT (-122.69258 47.91212)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Transportation and Warehousing</td>\n",
       "      <td>Port Ludlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>42</td>\n",
       "      <td>ChIJLah42szmj1QRZpfU3Vo2xTY</td>\n",
       "      <td>Oak Bay Rd &amp; Opp Olympus Blvd</td>\n",
       "      <td>Washington 98365, USA</td>\n",
       "      <td>bus_stop</td>\n",
       "      <td>47.941977</td>\n",
       "      <td>-122.688553</td>\n",
       "      <td>transportation</td>\n",
       "      <td>POINT (-122.68855 47.94198)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Transportation and Warehousing</td>\n",
       "      <td>Washington 98365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>44</td>\n",
       "      <td>ChIJ0Y_p64MCkFQRyYXYqJflZI8</td>\n",
       "      <td>Scatchet Head Rd at Bailey Rd (SB)</td>\n",
       "      <td>Washington 98236, USA</td>\n",
       "      <td>bus_stop</td>\n",
       "      <td>47.936720</td>\n",
       "      <td>-122.410862</td>\n",
       "      <td>transportation</td>\n",
       "      <td>POINT (-122.41086 47.93672)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Transportation and Warehousing</td>\n",
       "      <td>Washington 98236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>44</td>\n",
       "      <td>ChIJKW2_64MCkFQR4vXk6q4IizQ</td>\n",
       "      <td>Scatchet Head Rd at Bailey Rd (NB)</td>\n",
       "      <td>Washington 98236, USA</td>\n",
       "      <td>bus_stop</td>\n",
       "      <td>47.936706</td>\n",
       "      <td>-122.410775</td>\n",
       "      <td>transportation</td>\n",
       "      <td>POINT (-122.41078 47.93671)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Transportation and Warehousing</td>\n",
       "      <td>Washington 98236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>44</td>\n",
       "      <td>ChIJXSp2fn0CkFQRB9CdEXcj6Z4</td>\n",
       "      <td>Bailey Rd at Cultus Bay Rd (NB)</td>\n",
       "      <td>Washington 98236, USA</td>\n",
       "      <td>bus_stop</td>\n",
       "      <td>47.936590</td>\n",
       "      <td>-122.399243</td>\n",
       "      <td>transportation</td>\n",
       "      <td>POINT (-122.39924 47.93659)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Transportation and Warehousing</td>\n",
       "      <td>Washington 98236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4261 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      circle_id                           id  \\\n",
       "0             0  ChIJwTqOxGO1kVQR3ffcwUqPDTc   \n",
       "1             0  ChIJpZyerHu1kVQRAc6e7nFRTOA   \n",
       "2             0  ChIJ8SIqjWO1kVQR2blnwrvt0C4   \n",
       "3             0  ChIJ4ZaLfGO1kVQRKZIPKm91JmA   \n",
       "4             0  ChIJOYTHKWO1kVQRRXwvopTyBVw   \n",
       "...         ...                          ...   \n",
       "4256         42  ChIJD6bA4-Xgj1QRg1RuvTgcXe0   \n",
       "4257         42  ChIJLah42szmj1QRZpfU3Vo2xTY   \n",
       "4258         44  ChIJ0Y_p64MCkFQRyYXYqJflZI8   \n",
       "4259         44  ChIJKW2_64MCkFQR4vXk6q4IizQ   \n",
       "4260         44  ChIJXSp2fn0CkFQRB9CdEXcj6Z4   \n",
       "\n",
       "                                    name  \\\n",
       "0                   Safeway Fuel Station   \n",
       "1                           Local Wrench   \n",
       "2           Valvoline Instant Oil Change   \n",
       "3                        Chevron Belfair   \n",
       "4                        QFC Fuel Center   \n",
       "...                                  ...   \n",
       "4256        Paradise Bay Rd & S Bay Lane   \n",
       "4257       Oak Bay Rd & Opp Olympus Blvd   \n",
       "4258  Scatchet Head Rd at Bailey Rd (SB)   \n",
       "4259  Scatchet Head Rd at Bailey Rd (NB)   \n",
       "4260     Bailey Rd at Cultus Bay Rd (NB)   \n",
       "\n",
       "                                         address primary_type        lat  \\\n",
       "0             23961 WA-3, Belfair, WA 98528, USA  gas_station  47.453613   \n",
       "1     23530 WA-3 suite a, Belfair, WA 98528, USA   car_repair  47.447925   \n",
       "2           23970 N WA-3, Belfair, WA 98528, USA   car_repair  47.453070   \n",
       "3             23880 WA-3, Belfair, WA 98528, USA  gas_station  47.452338   \n",
       "4             201 WA-300, Belfair, WA 98528, USA  gas_station  47.453683   \n",
       "...                                          ...          ...        ...   \n",
       "4256                  Port Ludlow, WA 98365, USA     bus_stop  47.912121   \n",
       "4257                       Washington 98365, USA     bus_stop  47.941977   \n",
       "4258                       Washington 98236, USA     bus_stop  47.936720   \n",
       "4259                       Washington 98236, USA     bus_stop  47.936706   \n",
       "4260                       Washington 98236, USA     bus_stop  47.936590   \n",
       "\n",
       "             lon     primary_cat                     geometry  naics_code  \\\n",
       "0    -122.824365      automotive  POINT (-122.82436 47.45361)        44.0   \n",
       "1    -122.828294      automotive  POINT (-122.82829 47.44793)        81.0   \n",
       "2    -122.822240      automotive  POINT (-122.82224 47.45307)        81.0   \n",
       "3    -122.824376      automotive  POINT (-122.82438 47.45234)        44.0   \n",
       "4    -122.827552      automotive  POINT (-122.82755 47.45368)        44.0   \n",
       "...          ...             ...                          ...         ...   \n",
       "4256 -122.692577  transportation  POINT (-122.69258 47.91212)        48.0   \n",
       "4257 -122.688553  transportation  POINT (-122.68855 47.94198)        48.0   \n",
       "4258 -122.410862  transportation  POINT (-122.41086 47.93672)        48.0   \n",
       "4259 -122.410775  transportation  POINT (-122.41078 47.93671)        48.0   \n",
       "4260 -122.399243  transportation  POINT (-122.39924 47.93659)        48.0   \n",
       "\n",
       "                                   naics_definition         addr_simple  \n",
       "0                                      Retail Trade          23961 WA-3  \n",
       "1     Other Services (except Public Administration)  23530 WA-3 suite a  \n",
       "2     Other Services (except Public Administration)        23970 N WA-3  \n",
       "3                                      Retail Trade          23880 WA-3  \n",
       "4                                      Retail Trade          201 WA-300  \n",
       "...                                             ...                 ...  \n",
       "4256                 Transportation and Warehousing         Port Ludlow  \n",
       "4257                 Transportation and Warehousing    Washington 98365  \n",
       "4258                 Transportation and Warehousing    Washington 98236  \n",
       "4259                 Transportation and Warehousing    Washington 98236  \n",
       "4260                 Transportation and Warehousing    Washington 98236  \n",
       "\n",
       "[4261 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsop_gplc = gpd.read_file('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/BSOP_MSA/bspo_google_place_5000/google_placescat_5000_clean.geojson')\n",
    "google_naics_mapping = pd.read_csv('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/mapping_google_naics.csv')\n",
    "bsop_gplc = bsop_gplc.merge(google_naics_mapping[['SubCategory','naics_code','naics_definition']], left_on = 'primary_type', right_on='SubCategory', how=\"left\")\n",
    "bsop_gplc['addr_simple'] = bsop_gplc['address'].str.split(',', n=1).str[0]\n",
    "bsop_gplc = bsop_gplc.drop(columns=['SubCategory'])\n",
    "bsop_gplc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb84a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3456328818309201\n"
     ]
    }
   ],
   "source": [
    "bspo_osm = gpd.read_file('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/BSOP_MSA/bspo msa/bspo_osm.geojson')\n",
    "print(f\"{bspo_osm['name'].notna().sum() / len(bspo_osm)}\")\n",
    "bspo_osm = bspo_osm[bspo_osm['name'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc0b4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsop_gplc_osm = search_spatial_candidates(reference_gdf=bsop_gplc, compared_gdf=bspo_osm, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e6cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsop_gplc_osm = match_by_name(reference_gdf=bsop_gplc_osm, compared_gdf=bspo_osm, re_name_col = \"name\", comp_name_col = \"name\", comp_id_col =\"cat\", threshold=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1946c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsop_gplc_osm = address_score_check(reference_gdf=bsop_gplc_osm, compared_gdf=bspo_osm, addr_col_ref = \"addr_simple\", addr_col_cmp = \"address\", id_col = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cdf7a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 1781 rows...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f0cc21687c4d9f83f267f8b2ce2a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04866b625a046cfb11235b60f9be0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bsop_gplc_osm = calculate_similarity_check(bsop_gplc_osm, cat_col_ref = \"primary_type\", cat_col_cmp = \"matched_cat_main\", id_col = \"matched_id\", result_col =  \"category_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b3349f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4179770007040601"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsop_gplc_osm['matched_id'].notnull().sum() / len(bsop_gplc_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f67618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer the X and Y into float type and deal with the address score\n",
    "cols_to_fix = ['name_score', 'location_distance', 'address_score', 'category_sim']\n",
    "for col in cols_to_fix:\n",
    "    bsop_gplc_osm[col] = pd.to_numeric(bsop_gplc_osm[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1793c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bsop_gplc_osm[bsop_gplc_osm[\"matched_id\"].notna()].copy()\n",
    "\n",
    "N = 1000\n",
    "\n",
    "weights = df[\"primary_cat\"].map(\n",
    "    df[\"primary_cat\"].value_counts(normalize=True)\n",
    ")\n",
    "\n",
    "df_sample = df.sample(\n",
    "    n=N,\n",
    "    weights=weights,\n",
    "    random_state=42\n",
    ")\n",
    "df_sample[['id','name','addr_simple', 'naics_definition','matched_id','matched_name','matched_address','matched_cat_main','location_distance']].to_csv('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/bsop_gplc_osm_2000_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34eb4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_check = pd.read_csv('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/BSOP_MSA/bspo_google_comparison/bsop_gplc_osm_2000_sample.csv')\n",
    "df_sample_check = df_sample_check.drop(columns='location_distance')\n",
    "df_sample_check = df_sample_check.merge(bsop_gplc_osm[['id','name_score','location_distance','address_score','category_sim']], left_on=\"id\", right_on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632af2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_true\n",
       "1    735\n",
       "0    265\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_check['is_true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b895f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sample_check.copy()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[['name_score', 'location_distance', 'address_score', 'category_sim']]\n",
    "y = df['is_true']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "720efa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y  # keep the same proportion of True vs False in training set and test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "077a38a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78        66\n",
      "           1       0.91      0.95      0.93       184\n",
      "\n",
      "    accuracy                           0.89       250\n",
      "   macro avg       0.87      0.84      0.86       250\n",
      "weighted avg       0.89      0.89      0.89       250\n",
      "\n",
      "XGBoost AUC: 0.9371706192358367\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    enable_categorical=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False  \n",
    ")\n",
    "\n",
    "xgb_y_pred = xgb_clf.predict(X_test)\n",
    "xgb_y_prob = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_cr = classification_report(y_test, xgb_y_pred)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_y_prob)\n",
    "\n",
    "print(xgb_cr)\n",
    "print(\"XGBoost AUC:\", xgb_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09eeb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = bsop_gplc_osm['matched_id'].notnull()\n",
    "df_pred = bsop_gplc_osm.loc[mask].copy()\n",
    "\n",
    "feature_cols = ['name_score', 'location_distance', 'address_score', 'category_sim']\n",
    "\n",
    "X_new = scaler.transform(df_pred[feature_cols])\n",
    "df_pred['true_match_prob'] = xgb_clf.predict_proba(X_new)[:, 1]\n",
    "df_pred['is_true_match'] = df_pred['true_match_prob'] >= 0.5\n",
    "\n",
    "bsop_gplc_osm.loc[mask, 'is_true_match'] = df_pred['is_true_match']\n",
    "bsop_gplc_osm.loc[mask, 'true_match_prob'] = df_pred['true_match_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c22174ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_true_match\n",
       "True     1292\n",
       "False     489\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsop_gplc_osm['is_true_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0840647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsop_gplc_osm.drop(columns=['cand_ids','cand_dist_m']).to_file('/Users/houpuli/Redlining Lab Dropbox/HOUPU LI/POI research/BSOP_MSA/bspo_google_comparison/bsop_gplc_osm.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cabe21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "houpu_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
